{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Start with installing packages\n",
    "\n",
    "First thing you need to do is ensure you have the right packages installed. Later you will call them into your code using the __using__ function. Here, we first call the Pkg package, then apply the add() fuction from that library to install other packages we will need as shown in the next block.\n",
    "\n",
    "As we will be running a function from a Python library, we will also need to add the *scipy* package to the Julia's instance of Python. For that we will use the Conda package. \n",
    "\n",
    "To excecute a block, hit the __>| Run__ button from the above menu. If you already installed these packages before (e.g. directly from the Julia terminal), you don't need to run the following block because it will take ages to excecute!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg # calls the Pkg package\n",
    "Pkg.add(\"PyCall\") # applies the add() function from the Pkg library to install PyCall. This will take a while!\n",
    "Pkg.add(\"Glob\")\n",
    "Pkg.add(\"FileIO\")\n",
    "Pkg.add(\"PyPlot\")\n",
    "Pkg.add(\"Plots\")\n",
    "Pkg.add(\"DSP\")\n",
    "Pkg.add(\"Statistics\")\n",
    "Pkg.add(\"JLD2\")\n",
    "\n",
    "# you will also need to add the scipy package to python, for this we use Conda rather than Pkg:\n",
    "using Conda \n",
    "Conda.add(\"scipy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd() # this tells you which directory you are in. \n",
    "\n",
    "# Make sure that your script and the data files are all in the same working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varinfo()  # lets look at what we have in the workspace (variables in Julia's working memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Importing data\n",
    "\n",
    "Here you will import data using Glob and FileIO packages. You can read up about these packages here if you wish: \n",
    "\n",
    "https://github.com/vtjnash/Glob.jl\n",
    "\n",
    "https://github.com/JuliaIO/FileIO.jl \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Glob , FileIO\n",
    "data_package=glob(\"neuro_data.jld2\")\n",
    "rawSIG = load(data_package[1], \"rawSIG\")\n",
    "pretrial_time = load(data_package[1], \"pretrial_time\")\n",
    "laser = hcat(load(data_package[1], \"laser\"))\n",
    "trial_t1 = load(data_package[1], \"trial_t\")\n",
    "fs = load(data_package[1], \"fs\")\n",
    "\n",
    "vect_index=collect(1:size(rawSIG,1))  # generate a vector from 1:size of the rawSIG vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varinfo()  # lets look at what we have in the workspace (variables in Julia's working memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(rawSIG) \n",
    "\n",
    "# This will show you the size of the variable rawSIG, which should look like this: (401408,) \n",
    "# This means that the variable rawSIG is an array of size 401408 rows but no columns (i.e. it is a vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visualising data with different plotting libraries available in Julia\n",
    "\n",
    "Here we will look at <font color='blue'>PyPlot</font>  and <font color='blue'>Plots</font>. \n",
    "\n",
    "<font color='blue'>PyPlot</font> is a Python library which comes from matplotlib, so the syntax for <font color='blue'>PyPlot</font> in Julia is identical to the python version. <font color='blue'>PyPlot</font> was designed to be similar in use to MATLAB plots, and is therefore very popular. Read more here: https://github.com/JuliaPy/PyPlot.jl. A tutorial on the Python version can be found here: https://matplotlib.org/tutorials/introductory/pyplot.html where you can find extensive instructions. <font color='blue'>PyPlot</font> works by using <font color='blue'>PyCall</font>, a Julia package that runs an instance of Python inside Julia to run Python libraries. This is very convenient because Python is much more established than Julia, so <font color='blue'>PyCall</font> permits us to use anything from Python that isn't yet available in Julia. \n",
    "\n",
    "<font color='blue'>Plots</font> is a native Julia library which can have various backends, including Gr(), plotly(), and (confusingly), also a native Julia version of pyplot, which is called by pyplot(). You can read more here: https://docs.juliaplots.org/latest/\n",
    "\n",
    "Below we will compare <font color='blue'>PyPlot</font> (probably the most versatile plotting library) with <font color='blue'>Plots</font>; plotly(), which is for generating plots in html. If we swap between different plotting backends, Julia freaks out, so you might need to restart Julia and start from the top!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot; pygui(true) # you need to add pygui(), otherwise the plots will be stored in memory but not shown.\n",
    "# with pygui(), you will generate a new interactive window\n",
    "figure() # this calls a new figure\n",
    "PyPlot.plot(vect_index,rawSIG)\n",
    "PyPlot.plot(vect_index,1000*laser)\n",
    "PyPlot.legend([\"rawSIG\", \"laser displacement\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots; plotly() # here we are using the plotly backend. Try gr() or pyplot() instead\n",
    "Plots.plot(vect_index,rawSIG, hover=vect_index, label = \"rawSIG\") #plot rawSIG (first row, all columns), display x variable on hover\n",
    "Plots.plot!(vect_index,1000*laser, label = \"laser displacement\", hover=1000*laser[1,:])\n",
    "# once plotted, you can interact with the plot using the tools above the plot which become visible as you hover your mouse over the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filtering data\n",
    "\n",
    "We will use the Digital signal processing package <font color='blue'>DSP</font> for filtering our data. More about what this package can do can be found here: https://github.com/JuliaDSP/DSP.jl. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DSP  # this is calling the DSP package which has tools for digital signal processing\n",
    "bpass = 300 # define Bandpass filter at 300 Hz\n",
    "bstop = 5000 # define Bandstop filter at 5000 Hz\n",
    "responsetype = Bandpass(bpass, bstop, fs = fs) # standard filtering use 300-5000\n",
    "designmethod = Butterworth(6)\n",
    "HFdata = filtfilt(digitalfilter(responsetype, designmethod), rawSIG)\n",
    "negHFdata = -HFdata # convention is to invert signal of extracellular recordings (upward deflection represents action potentials)\n",
    "varinfo() # view workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view signals:\n",
    "figure()\n",
    "PyPlot.plot(vect_index[209000:212000],rawSIG[209000:212000]) #plot rawSIG: first row, columns (samples) between 209000 and 212000\n",
    "PyPlot.plot(vect_index[209000:212000],1000*laser[209000:212000])\n",
    "PyPlot.plot(vect_index[209000:212000],negHFdata[209000:212000])\n",
    "PyPlot.legend([\"rawSIG\",  \"laser displacement\", \"negHFdata\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Reorganise our signal into multiple trials\n",
    "\n",
    "In this experiment we evoked a mechanical pulse 10 times with an interval of about 1s between stimuli. \n",
    "\n",
    "Lets now lets chop up our signal based on the peak of each mechanical stimulus. For this, we need to determine where to split up each trial (how manny samples before and after the stimulus). Lets base the chopping point from the peak of our laser signal. \n",
    "\n",
    "To do this, we will a python function called *find_peaks* which comes from SciPy.org, freeware with lots of great tools written in Python, such as for signal processing: <font color='blue'>scipy.signal</font>. See: https://docs.scipy.org/doc/scipy/reference/tutorial/signal.html for more details on what is contained in <font color='blue'>scipy.signal</font>, and from that site you can find the **scipy.signal.find_peaks** page.\n",
    "\n",
    "To access this Python library and function, we will use <font color='blue'>PyCall</font>, which will run a Python session inside Julia. If we wanted to, we could take the open source code and make our own *find_peak* fuction in Julia (someone has done this already: https://github.com/tungli/Findpeaks.jl), but here we are demonstrating how we can use <font color='blue'>PyCall</font> to run any Python code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall # import the PyCall library, which allows us to use python commands\n",
    "\n",
    "scisig = pyimport(\"scipy.signal\") # import the scipy signal processing library from python. This contains the find_peaks function. \n",
    "\n",
    "stim_ind, pkHeights = scisig.find_peaks(1000*laser[:,1], height = 15, distance = 16000) \n",
    "# use the python find peak function to find all the indexes of peaks that are greater than 15 and only allow one peak per 16000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkHeights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Making a function\n",
    "\n",
    "We will now make a fucntion that will chop up the signal according to the location of the found peaks. We will define this function as called *split_trials*. A function contain input argumnents and may or maynot have an output. In this case, we will take in some arguments that we need to generate the chopped sequence, so that we will convert a vector (single row) into an array of 10 vectors stacked on top of each other. \n",
    "\n",
    "If you provide a string before a function, you can access it from a help menu. So good coding practice will ensure our function well described: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "split_trials() takes a single vector and splits it into a 2D array according to the a vector\n",
    "which contains the indexes of where to split the vector. You define how far before and after\n",
    "the split location for each trial. This function also permits shifting relative to the split point.\n",
    "\n",
    "%%%%%%% Inputs %%%%%%%\n",
    "\n",
    "- amp_signal: is an array containing the data from the electrode of interest\n",
    "\n",
    "- amp_samplerate: is a value containing the samplerate from recording\n",
    "\n",
    "- stms: is a row vector that indicates the time that each stimulus artifact occurred in the recording\n",
    "\n",
    "- trial_length: is the length of the trials that the data will be split into (in samples)\n",
    "\n",
    "- Lag_time: how long after the stimulus artefact each trial will begin (usually '0', but can be\n",
    "later for chopping up windows for machine learning etc)\n",
    "\n",
    "- pre_trial_length: the amount of recording before the stimulus artefact to be included (in samples)\n",
    "\n",
    "%%%%%%% Outputs %%%%%%%\n",
    "\n",
    "- trial_data: an n*m matrix conatining all the data for each trial\n",
    "     n is the number of trials and m is the length of the trials in sample\n",
    "\"\"\"\n",
    "function split_trials(amp_signal, amp_samplerate, stms, trial_length, lag_time, pre_trial_length)\n",
    "    trial_data = [];\n",
    "    # creating the matrices containg each trial as recorded by each of seven electrodes\n",
    "    for k = 1:size(stms,2)\n",
    "        strts = convert(Int,floor(stms[1,k]+lag_time)-pre_trial_length)\n",
    "        t_end = convert(Int,strts+(trial_length-1))\n",
    "        if t_end > length(amp_signal)\n",
    "            println(\"The end of the final trial was too close to the end of the\\n\",\n",
    "            \"recording to acquire background data for the last signal\") &&  break\n",
    "        else\n",
    "            # trial_data[k,:] = amp_signal[strts:t_end]\n",
    "            push!(trial_data, amp_signal[strts:t_end])\n",
    "        end\n",
    "    end\n",
    "    return trial_data\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can request docmentation for a fuction by using @doc macro. \n",
    "# You can provide documentation for your fuction by including it as a string enclosed by triple quotes as we did above. \n",
    "\n",
    "@doc split_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the new function\n",
    "\n",
    "We will now apply our new function to split our signal (negHFdata) and the laser displacement analogue signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data = split_trials(negHFdata, fs, stim_ind', 5000,  0, 1000) # split the data around the laser peaks, make it a 5000 sample sequence\n",
    "trial_laser = split_trials(laser, fs, stim_ind', 5000,  0, 1000) # split the laser signal around the laser peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. View filtered signals\n",
    "\n",
    "To plot any signls, we need x and y variables. To plot a signal against time, we have to generate a time vector, as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_vect=-1000:1:3999 # this is the 5000 vector starting from -1000 (as we had applied for our split_trial fuction)\n",
    "time_vect = (time_vect/fs)*1000 # we need to convert each sample to the correct time stamp, so we need to know the sample frequency (fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can plot the signals against time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  view a single signal (individual axes)\n",
    "\n",
    "#############  view signals (individual axes)\n",
    "trial_to_inspect = 3 # here we can choose which trial we want to inspect, just change the value to between 1 and 10. \n",
    "figure()\n",
    "PyPlot.plot(time_vect, trial_data[trial_to_inspect])\n",
    "PyPlot.plot(time_vect, 1000*trial_laser[trial_to_inspect])\n",
    "\n",
    "PyPlot.legend([\"trial data\", \"displacement\"])\n",
    "PyPlot.xlabel(\"milliseconds\")\n",
    "PyPlot.ylabel(\"trial data (uV) | displacement (um)\")\n",
    "PyPlot.title(\"Signal from trial no. $trial_to_inspect\") # putting a $ in front of a variable converts the value into a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view all 10 signals at once, using a <font color='blue'>**for**</font> loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view all trials a single figure with 10 subplots:\n",
    "\n",
    "No_trials=size(trial_data,1) # number of trials\n",
    "fig1, ax1 = subplots(No_trials, 1, sharex=\"all\", sharey=\"all\") # define subplots and which axes are shared (for zooming all at once)\n",
    "for i = 1:No_trials # for each trail plot the data and the displacement\n",
    "    ax1[i,1].plot(time_vect, trial_data[i])\n",
    "    ax1[i,1].plot(time_vect, 1000*trial_laser[i])\n",
    "    # ax1[i,1].plot((spike_ind[i]/30) .-300, pkH[i],\"r.\", markersize = 6, color = \"red\")\n",
    "end\n",
    "\n",
    "fig1.legend([\"trial data\", \"displacement\"])\n",
    "fig1.text(0.5, 0.05, \"milliseconds\", ha=\"center\", va=\"center\")\n",
    "fig1.text(0.05, 0.5, \"trial data (uV) | displacement (um)\", ha=\"center\", va=\"center\", rotation=\"vertical\")\n",
    "fig1.suptitle(\"Signals of $No_trials trials\") # add title to subplots\n",
    "fig1.legend([\"trial data\", \"displacement (microns)\"]) # add legend to subplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Event detection\n",
    "\n",
    "The easiest way to detect units is to select signals that reach a certain threshold. Here we will determine a threshold and detect signals that exceed this threshold. For that, we will calculate the threshold for some standard deviation above the mean of a signal over a range before the event has occured. Recall that our signals have 1000 samples before the stimulus, and 4000 after. So we can determine our background from the first ~1000 samples, as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "HFdata_mean=mean(trial_data) # this will generate a signal representing the mean of the 10 signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets plot this for some examples: \n",
    "\n",
    "figure()\n",
    "PyPlot.plot(time_vect,trial_data[1])\n",
    "PyPlot.plot(time_vect,trial_data[5])\n",
    "PyPlot.plot(time_vect,trial_data[10])\n",
    "PyPlot.plot(time_vect,HFdata_mean, color=\"black\", linewidth=2)\n",
    "PyPlot.legend([\"trial 1\", \"trial 5\", \"trial 10\", \"mean of 10 trials\"])\n",
    "# we can see this doesnt capture all the signals well because of the jitter (need to zoom in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now calculate the mean over the background range (i.e. first 1000 samples), and define a threshold to be 3 standard deviations greater than the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkgnd_1= 3 * std(trial_data[1][1:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets plot the backgorund threshold and the peaks above this threshold on the same plot (if you closed the previous plot, generate the figure again before you execute the next code block)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets find all peaks greater than bkgnd, and plot on same graph as before (note we arn't calling a new figure):\n",
    "\n",
    "ind_x, pks_x = scisig.find_peaks(trial_data[1], height = bkgnd_1) # use \"find_peaks\" function from python scisig library to find all peaks in x greater than the height bkgnd_1\n",
    "PyPlot.plot(time_vect,bkgnd_1*ones(5000,1), label = \"3x SD above background noise (bkgnd_1)\")\n",
    "PyPlot.plot((ind_x .-1000)/fs*1000,pks_x[\"peak_heights\"], \"r.\", markersize = 6, color = \"red\")\n",
    "PyPlot.legend([\"trial 1\", \"trial 5\", \"trial 10\", \"mean of 10 trials\",\"detection threshold\", \"peaks above threshold\"])\n",
    "# this last expression gets the index for the peak, subtracts 1000 because we are converting to time and the vector starts at -1000 samples from time zero\n",
    "# we then divide by the sample frequency (fs) x1000 to convert our x-axis to ms rather than indicies of the vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets do this for all trials\n",
    "\n",
    "inds_trials = [] # need to declare the variable outside a for loop becauase we will be calling in from inside the for loop\n",
    "pks_trials = [] \n",
    "for i = 1: 10\n",
    "    ind_x, pks_x = scisig.find_peaks(trial_data[i], height = 3 * std(trial_data[i][1:1000]))\n",
    "    push!(inds_trials, ind_x')\n",
    "    push!(pks_trials, pks_x[\"peak_heights\"]')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pks_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it works on a random example:\n",
    "\n",
    "figure()\n",
    "PyPlot.plot(time_vect,trial_data[7])\n",
    "PyPlot.plot((inds_trials[7] .-1000)[1,:]/fs*1000,pks_trials[7], \"r.\", markersize = 6, color = \"red\")\n",
    "# looks ok; try substituting another number instead of 7...\n",
    "# can anyone tell me why we need the [1,:]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot all the signals on separate subplots:\n",
    "\n",
    "fig2, ax2 = subplots(No_trials, 1, sharex=\"all\", sharey=\"all\") # define subplots and which axes are shared\n",
    "for i = 1:No_trials # for each trail plot the data and the displacement\n",
    "    ax2[i,1].plot(time_vect, trial_data[i])\n",
    "    ax2[i,1].plot(time_vect, 1000*trial_laser[i])\n",
    "    ax2[i,1].plot((inds_trials[i] .-1000)[1,:]/fs*1000, pks_trials[i],\"r.\", markersize = 6, color = \"red\")\n",
    "end\n",
    "fig2.suptitle(\"Signals of $No_trials trials\") # add title to subplots\n",
    "fig2.legend([\"trial data\", \"displacement (microns)\", \"detected peaks\"]) # add legend to subplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Building and quantifying raster plots\n",
    "\n",
    "To perform some analysis on the neuronal behavoural response to the stimulus, it is convenient to observe the pattern of firing relative to multiple trials. A rasterplot is a great way to observe this, and a frequency histogram is a great way to quantify the activty from multiple trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make a raster for all 10 trials and see what it looks like\n",
    "\n",
    "figure()\n",
    "for i =1:No_trials\n",
    "PyPlot.plot((inds_trials[i] .-1000)/fs*1000, i*ones(size(pks_trials[i])),\"r.\", markersize = 6, color = \"red\")\n",
    "end\n",
    "# note that the raster is in the reverse order to the previous figure; why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets add a frequency histogram to count the number of events above threshold:\n",
    "\n",
    "binwidth=1 #define bin width, you can change this and see how it looks\n",
    "pretrial_length = 1000 # each trial has 1000 samples before it\n",
    "trial_len = 5000 # each trial has 5000 samples in total\n",
    "bin_edges=collect(round(-pretrial_length/fs*1000):binwidth: round((-pretrial_length+trial_len)/fs*1000))\n",
    "\n",
    "inds_trials_flat = sort(reduce(hcat,inds_trials)') # concatinate all vectors horixontally, then sort in order\n",
    "inds_trials_flat = inds_trials_flat .-1000 # subtract 1000 (range = -1000:4000, i.e. 5000 length vector)\n",
    "\n",
    "hist(inds_trials_flat/fs*1000, bins=bin_edges, alpha = 0.5) # generate a histogram and associated data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now add to the raster and link the axes\n",
    "fig3, ax3 = subplots(2, 1, sharex=\"all\") # start a new plot\n",
    "for i =1:No_trials\n",
    "ax3[1,1].plot((inds_trials[i] .-1000)/fs*1000, i*ones(size(pks_trials[i])),\"r.\", markersize = 6, color = \"red\")\n",
    "end\n",
    "ax3[2,1].hist(inds_trials_flat/fs*1000, bins=bin_edges, alpha = 0.5)\n",
    "\n",
    "\n",
    "ax3[1,1].set(ylabel = \"Trial number\")\n",
    "ax3[2,1].set(ylabel = \"Frequency\")\n",
    "ax3[1,1].legend([\"rasterplot of 10 trials\"]) \n",
    "ax3[2,1].legend([\"histogram of rasterplot\"]) \n",
    "\n",
    "fig3.text(0.5, 0.05, \"milliseconds\", ha=\"center\", va=\"center\")\n",
    "fig3.text(-50, 0.5, \"Trial number\", ha=\"center\", va=\"center\")\n",
    "fig3.suptitle(\"Signals of $No_trials trials\") "
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
